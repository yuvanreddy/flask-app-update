name: Terraform EKS Infrastructure

on:
  push:
    branches:
      - master
    paths:
      - 'terraform-eks/**'
  pull_request:
    branches:
      - master
    paths:
      - 'terraform-eks/**'
  workflow_dispatch:
    inputs:
      action:
        description: 'Terraform Action'
        required: true
        default: 'plan'
        type: choice
        options:
          - plan
          - apply
          - destroy

permissions:
  id-token: write
  contents: read
  pull-requests: write

env:
  AWS_REGION: us-east-1
  TERRAFORM_VERSION: 1.6.0
  WORKING_DIR: ./terraform-eks
  CLUSTER_NAME: flask-eks

jobs:
  terraform-check:
    name: Terraform Validation & Security
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}

      - name: Terraform Format Check
        working-directory: ${{ env.WORKING_DIR }}
        run: terraform fmt -check -recursive
        continue-on-error: true

      - name: Terraform Init
        working-directory: ${{ env.WORKING_DIR }}
        run: terraform init -backend=false

      - name: Terraform Validate
        working-directory: ${{ env.WORKING_DIR }}
        run: terraform validate

      - name: Run tfsec (Terraform Security Scanner)
        uses: aquasecurity/tfsec-action@v1.0.3
        with:
          working_directory: ${{ env.WORKING_DIR }}
          soft_fail: true

      - name: Run Checkov (IaC Security)
        uses: bridgecrewio/checkov-action@master
        with:
          directory: ${{ env.WORKING_DIR }}
          framework: terraform
          soft_fail: true
          output_format: sarif
          output_file_path: checkov-results.sarif

      - name: Upload Checkov results
        uses: github/codeql-action/upload-sarif@v3
        continue-on-error: true
        if: always()
        with:
          sarif_file: checkov-results.sarif

  terraform-plan:
    name: Terraform Plan
    runs-on: ubuntu-latest
    needs: terraform-check
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS Credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}

      - name: Terraform Init
        working-directory: ${{ env.WORKING_DIR }}
        run: terraform init

      - name: Terraform Plan
        working-directory: ${{ env.WORKING_DIR }}
        run: |
          terraform plan \
            -var="cluster_name=${{ env.CLUSTER_NAME }}" \
            -out=tfplan.binary

      - name: Convert Plan to JSON
        working-directory: ${{ env.WORKING_DIR }}
        run: terraform show -json tfplan.binary > tfplan.json

      - name: Upload Plan Artifact
        uses: actions/upload-artifact@v4
        with:
          name: terraform-plan
          path: |
            ${{ env.WORKING_DIR }}/tfplan.binary
            ${{ env.WORKING_DIR }}/tfplan.json
          retention-days: 5

      - name: Post Plan to PR
        uses: actions/github-script@v7
        if: github.event_name == 'pull_request'
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const plan = fs.readFileSync('${{ env.WORKING_DIR }}/tfplan.json', 'utf8');
            const planSummary = plan.substring(0, 30000); // Truncate for comment size
            
            const output = `#### Terraform Plan
            
            <details><summary>Show Plan (truncated)</summary>
            
            \`\`\`json
            ${planSummary}
            \`\`\`
            
            </details>
            
            *Pushed by: @${{ github.actor }}, Action: \`${{ github.event_name }}\`*
            
            **Note:** Plan must be reviewed and manually approved via workflow_dispatch for apply.`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: output
            })

  terraform-apply:
    name: Terraform Apply
    runs-on: ubuntu-latest
    needs: terraform-plan
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'apply'
    environment:
      name: production
      url: https://console.aws.amazon.com/eks/home?region=${{ env.AWS_REGION }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS Credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}

      - name: Terraform Init
        working-directory: ${{ env.WORKING_DIR }}
        run: terraform init

      - name: Download Plan Artifact
        uses: actions/download-artifact@v4
        with:
          name: terraform-plan
          path: ${{ env.WORKING_DIR }}

      - name: Terraform Apply
        working-directory: ${{ env.WORKING_DIR }}
        run: terraform apply -auto-approve tfplan.binary

      - name: Wait for EKS cluster to be ready
        run: |
          echo "Waiting for EKS cluster to be fully ready..."
          sleep 60
          aws eks wait cluster-active --name ${{ env.CLUSTER_NAME }} --region ${{ env.AWS_REGION }}

      - name: Verify EBS CSI Driver
        run: |
          aws eks update-kubeconfig --name ${{ env.CLUSTER_NAME }} --region ${{ env.AWS_REGION }}
          echo "Checking EBS CSI Driver pods..."
          kubectl get pods -n kube-system -l app=ebs-csi-controller
          echo "Checking storage classes..."
          kubectl get storageclass

      - name: Get EKS Cluster Info
        working-directory: ${{ env.WORKING_DIR }}
        run: |
          echo "### EKS Cluster Updated" >> $GITHUB_STEP_SUMMARY
          
          CLUSTER_NAME=$(terraform output -raw cluster_name)
          CLUSTER_ENDPOINT=$(terraform output -raw cluster_endpoint)
          GITHUB_ROLE=$(terraform output -raw github_deployer_role_arn)
          
          echo "**Cluster Name:** \`${CLUSTER_NAME}\`" >> $GITHUB_STEP_SUMMARY
          echo "**Cluster Endpoint:** \`${CLUSTER_ENDPOINT}\`" >> $GITHUB_STEP_SUMMARY
          echo "**GitHub Role ARN:** \`${GITHUB_ROLE}\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Configure kubectl:**" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`bash" >> $GITHUB_STEP_SUMMARY
          echo "aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${CLUSTER_NAME}" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY

      - name: Upload Terraform Outputs
        uses: actions/upload-artifact@v4
        with:
          name: terraform-outputs
          path: ${{ env.WORKING_DIR }}/outputs.json
          retention-days: 30

  terraform-destroy:
    name: Terraform Destroy
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'destroy'
    environment:
      name: production-destroy
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: WARNING - Destruction Initiated
        run: |
          echo "::warning::DESTROYING ENTIRE EKS CLUSTER AND ALL RESOURCES"
          echo "This will delete:"
          echo "  - EKS Cluster: ${{ env.CLUSTER_NAME }}"
          echo "  - All node groups and pods"
          echo "  - VPC and networking"
          echo "  - IAM roles"
          echo "  - Load balancers"
          sleep 10

      - name: Configure AWS Credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}

      - name: Terraform Init
        working-directory: ${{ env.WORKING_DIR }}
        run: terraform init

      - name: Install kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: 'latest'

      - name: Update kubeconfig
        run: |
          aws eks update-kubeconfig --name ${{ env.CLUSTER_NAME }} --region ${{ env.AWS_REGION }} || true

      - name: Remove Helm releases (if accessible)
        run: |
          echo "Attempting to remove Helm releases..."
          helm uninstall aws-load-balancer-controller -n kube-system || echo "Could not uninstall via Helm, will remove from state"
        continue-on-error: true

      - name: Remove Helm release from Terraform state
        working-directory: ${{ env.WORKING_DIR }}
        run: |
          terraform state rm helm_release.aws_load_balancer_controller || echo "Helm release not in state"
        continue-on-error: true

      - name: Terraform Destroy
        working-directory: ${{ env.WORKING_DIR }}
        run: |
          terraform destroy \
            -var="cluster_name=${{ env.CLUSTER_NAME }}" \
            -auto-approve

      - name: Post Destruction Summary
        run: |
          echo "### EKS Cluster Destroyed" >> $GITHUB_STEP_SUMMARY
          echo "All infrastructure has been removed." >> $GITHUB_STEP_SUMMARY
          echo "**Cluster:** ${{ env.CLUSTER_NAME }}" >> $GITHUB_STEP_SUMMARY
          echo "**Timestamp:** $(date)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "To recreate, run workflow_dispatch with 'apply' action." >> $GITHUB_STEP_SUMMARY