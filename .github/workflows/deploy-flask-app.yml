name: Deploy Flask App to EKS (with ALB)

on:
  workflow_dispatch:
    inputs:
      image_tag:
        description: 'Docker image tag to deploy'
        required: false
        default: "master"

permissions:
  id-token: write
  contents: read

env:
  AWS_REGION: us-east-1
  EKS_CLUSTER_NAME: flask-eks
  NAMESPACE: default

  # Workload names
  DEPLOYMENT: flask-app
  CONTAINER: flask
  SERVICE: flask-svc

  # Cloudsmith (registry)
  REG_SERVER: docker.cloudsmith.io
  REG_SECRET: cloudsmith-regcred
  APP_SA: flask-app-sa

  # Ingress/ALB settings
  INGRESS_NAME: flask-alb
  INGRESS_CLASS: alb
  INGRESS_GROUP: flask-demo
  HEALTHCHECK_PATH: /health
  BACKEND_PORT: 5000

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Install kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: 'latest'

      - name: Update kubeconfig for EKS
        run: |
          aws eks update-kubeconfig --name "${EKS_CLUSTER_NAME}" --region "${AWS_REGION}"

      - name: Ensure namespace exists
        run: |
          kubectl get ns "${NAMESPACE}" >/dev/null 2>&1 || kubectl create ns "${NAMESPACE}"

      # --- Cloudsmith image pull secret + SA (CI-managed) ---
      - name: Create/Update Cloudsmith imagePullSecret
        run: |
          kubectl create secret docker-registry "${REG_SECRET}" \
            --namespace "${NAMESPACE}" \
            --docker-server="${REG_SERVER}" \
            --docker-username="${{ secrets.CLOUDSMITH_USERNAME }}" \
            --docker-password="${{ secrets.CLOUDSMITH_API_KEY }}" \
            --docker-email="devnull@example.com" \
            --dry-run=client -o yaml | kubectl apply -f -

      - name: Ensure workload ServiceAccount uses imagePullSecret
        run: |
          kubectl apply -f - <<EOF
          apiVersion: v1
          kind: ServiceAccount
          metadata:
            name: ${APP_SA}
            namespace: ${NAMESPACE}
          imagePullSecrets:
          - name: ${REG_SECRET}
          EOF

      # --- Optional: create Service if missing (ClusterIP on port 80 -> containerPort BACKEND_PORT) ---
      - name: Ensure Service exists
        run: |
          if ! kubectl -n "${NAMESPACE}" get svc "${SERVICE}" >/dev/null 2>&1; then
            kubectl apply -f - <<EOF
          apiVersion: v1
          kind: Service
          metadata:
            name: ${SERVICE}
            namespace: ${NAMESPACE}
            labels:
              app: ${DEPLOYMENT}
          spec:
            selector:
              app: ${DEPLOYMENT}
            ports:
            - name: http
              port: 80
              targetPort: ${BACKEND_PORT}
            type: ClusterIP
          EOF
          fi

      # --- Create Deployment if not exists ---
      - name: Ensure Deployment exists
        env:
          IMAGE_TAG: ${{ github.event.inputs.image_tag || 'latest' }}
        run: |
          FULL_IMAGE="docker.cloudsmith.io/${CLOUDSMITH_REPO}/${IMAGE_NAME}:${IMAGE_TAG}"
          
          if ! kubectl -n "${NAMESPACE}" get deploy "${DEPLOYMENT}" >/dev/null 2>&1; then
            echo "Creating new deployment with image: ${FULL_IMAGE}"
            kubectl apply -f k8s/deployment.yaml
          fi
          
          # Update image to the specific tag
          echo "Updating deployment to use image: ${FULL_IMAGE}"
          kubectl set image deployment/${DEPLOYMENT} ${CONTAINER}=${FULL_IMAGE} -n ${NAMESPACE}
          
          # Add annotation to force rolling update
          kubectl patch deployment ${DEPLOYMENT} -n ${NAMESPACE} -p \
            "{\"spec\":{\"template\":{\"metadata\":{\"annotations\":{\"deployedAt\":\"$(date +'%s')\"}}}}}"

      # --- Ensure ALB Ingress exists (internet-facing) ---
      - name: Ensure Ingress (AWS Load Balancer Controller) exists
        run: |
          if ! kubectl -n "${NAMESPACE}" get ingress "${INGRESS_NAME}" >/dev/null 2>&1; then
            kubectl apply -f - <<EOF
          apiVersion: networking.k8s.io/v1
          kind: Ingress
          metadata:
            name: ${INGRESS_NAME}
            namespace: ${NAMESPACE}
            annotations:
              alb.ingress.kubernetes.io/scheme: internet-facing
              alb.ingress.kubernetes.io/target-type: ip
              alb.ingress.kubernetes.io/group.name: ${INGRESS_GROUP}
              alb.ingress.kubernetes.io/healthcheck-path: ${HEALTHCHECK_PATH}
              alb.ingress.kubernetes.io/listen-ports: '[{"HTTP":80}]'
          spec:
            ingressClassName: ${INGRESS_CLASS}
            rules:
            - http:
                paths:
                - path: /
                  pathType: Prefix
                  backend:
                    service:
                      name: ${SERVICE}
                      port:
                        number: 80
          EOF
          fi

      # --- Restart pods to ensure fresh pull with creds ---
      - name: Rollout restart and wait
        run: |
          kubectl -n "${NAMESPACE}" rollout restart deploy "${DEPLOYMENT}"
          kubectl -n "${NAMESPACE}" rollout status deploy "${DEPLOYMENT}" --timeout=300s

      # --- Wait for ALB hostname and print endpoints ---
      - name: Fetch ALB address
        id: alb
        run: |
          echo "Waiting for Ingress address ..."
          for i in $(seq 1 60); do
            HOST=$(kubectl -n "${NAMESPACE}" get ingress "${INGRESS_NAME}" -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || true)
            if [ -n "$HOST" ]; then echo "host=$HOST" >> $GITHUB_OUTPUT; exit 0; fi
            sleep 10
          done
          echo "host=" >> $GITHUB_OUTPUT

      - name: Summary
        run: |
          echo "=== Pods ==="
          kubectl -n "${NAMESPACE}" get pods -l app=${DEPLOYMENT} -o wide || true
          echo
          echo "=== Service ==="
          kubectl -n "${NAMESPACE}" get svc ${SERVICE} -o wide || true
          echo
          echo "=== Ingress ==="
          kubectl -n "${NAMESPACE}" get ingress ${INGRESS_NAME} -o wide || true
          echo
          if [ -n "${{ steps.alb.outputs.host }}" ]; then
            echo "App URL: http://${{ steps.alb.outputs.host }}/"
            echo "Health:  http://${{ steps.alb.outputs.host }}${HEALTHCHECK_PATH}"
          else
            echo "ALB is still provisioning. Re-run 'kubectl get ingress -n ${NAMESPACE}' to check."
          fi